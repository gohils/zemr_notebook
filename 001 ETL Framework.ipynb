{"cells":[{"cell_type":"markdown","source":["### ETL Framework base clase and Extract (to read data from input file), Transform (dataframes) and Load (write final result into file or DW) class"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"760dfc5b-a898-4721-bf74-c7ba46d766cc"}}},{"cell_type":"code","source":["\nclass EtlBase:\n    def __init__(self):\n        pass\n\n    def run(self):\n        pass\n\nclass Extract(EtlBase):\n    def __init__(self,input_dataframe,input_dict_params=None):\n        super().__init__()\n        self.input_df = input_dataframe\n        self.input_params = input_dict_params\n        # print(\"init from extract\")        \n\n    def run(self):\n        print(\"run Extract\")\n        result = str(self.input_df) + '_Extract'\n        return result    \n\nclass Transform1(EtlBase):\n    def __init__(self,input_dataframe,input_dict_params=None):\n        super().__init__()\n        self.input_df = input_dataframe\n        self.input_params = input_dict_params\n        # print(\"init from Transform1\")        \n\n    def run(self):\n        print(\"run Transform1\")\n        result = str(self.input_df) + '_Transform1'\n        return result    \n\nclass Transform2(EtlBase):\n    def __init__(self,input_dataframe,input_dict_params=None):\n        super().__init__()\n        self.input_df = input_dataframe\n        self.input_params = input_dict_params\n        # print(\"init from Transform2\")        \n\n    def run(self):\n        print(\"run Transform2\")\n        result = str(self.input_df) + '_Transform2'\n        return result    \n\nclass Load(EtlBase):\n    def __init__(self,input_dataframe,input_dict_params=None):\n        super().__init__()\n        self.input_df = input_dataframe\n        self.input_params = input_dict_params\n        # print(\"init from Load\")        \n\n    def run(self):\n        print(\"run Load\")\n        result = str(self.input_df) + '_Load'\n        return result    \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c03c0ee-3b1e-4811-b8ad-db10bb65f114"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["input_df = \"df1\"\napp_input_param =\"zparams1\"\n\nresult = Extract(input_dataframe=input_df,input_dict_params=app_input_param).run()\nprint(result)\n\ntaks1 = \"Extract(input_dataframe=input_df,input_dict_params=app_input_param).run()\"\ntaks2 = \"Transform1(input_dataframe=input_df,input_dict_params=app_input_param).run()\"\ntaks3 = \"Transform2(input_dataframe=input_df,input_dict_params=app_input_param).run()\"\ntaks4 = \"Load(input_dataframe=input_df,input_dict_params=app_input_param).run()\"\n\netl_work_flow = [taks1,taks2,taks3,taks4]\n\nprint(\"start of ETL workflow ====> \", input_df)\nfor task in etl_work_flow:\n    input_df :object = eval(task)\n\nprint(\"End of ETL workflow ====> \", input_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3b244ce-b45f-4be5-8f72-637669242ff3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"run Extract\ndf1_Extract\nstart of ETL workflow ====>  df1\nrun Extract\nrun Transform1\nrun Transform2\nrun Load\nEnd of ETL workflow ====>  df1_Extract_Transform1_Transform2_Load\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["run Extract\ndf1_Extract\nstart of ETL workflow ====>  df1\nrun Extract\nrun Transform1\nrun Transform2\nrun Load\nEnd of ETL workflow ====>  df1_Extract_Transform1_Transform2_Load\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### define workflow with json file"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7ced3d4-fd13-43f3-8b41-383a8fe7c52d"}}},{"cell_type":"code","source":["import json\nimport os\n# {\"extract\":\"input_file_process\",\"transform\":[\"tranform1\",\"transform2\"], \"load\" : \"output_path\"}\njson_str = {\"extract\":\"Extract(input_dataframe=input_df,input_dict_params=app_input_param).run()\",\n\"transform\":[\"Transform1(input_dataframe=input_df,input_dict_params=app_input_param).run()\",\n\"Transform2(input_dataframe=input_df,input_dict_params=app_input_param).run()\"], \n\"load\" : \"Load(input_dataframe=input_df,input_dict_params=app_input_param).run()\"}\n\nfile_path = './etl_pipe1_config.json'\nwith open(file_path,'w') as file:\n    json.dump(json_str,file)\n\nconfigJson = open(file_path,'r')\nconfig_dict = json.load(configJson)\n\n# print(config_dict)\n# print(type(config_dict))\n\ntasks_list = []\ntasks_list.append(config_dict['extract'])\ntasks_list = tasks_list + config_dict['transform']\ntasks_list.append(config_dict['load'])\n\ninput_df = \"df1\"\napp_input_param =\"zparams1\"\nprint(\"start of ETL json workflow =***********************> \", input_df)\nfor task in tasks_list:\n    input_df :object = eval(task)\n\nprint(\"End of ETL json workflow =***********************> \", input_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"554411a1-20eb-4bd2-9b20-cce487238766"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"start of ETL json workflow =***********************>  df1\nrun Extract\nrun Transform1\nrun Transform2\nrun Load\nEnd of ETL json workflow =***********************>  df1_Extract_Transform1_Transform2_Load\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["start of ETL json workflow =***********************>  df1\nrun Extract\nrun Transform1\nrun Transform2\nrun Load\nEnd of ETL json workflow =***********************>  df1_Extract_Transform1_Transform2_Load\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### read config file from the git repo"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4ec63d3-064b-4456-afce-3c04f6b0b3f0"}}},{"cell_type":"code","source":["configJson = open(file_path,'r')\nconfig_dict = json.load(configJson)\n\nimport requests\nurl = 'https://raw.githubusercontent.com/gohils/zemr_notebook/master/etl_pipe1_config.json'\nf = requests.get(url)\n# The .json() method automatically parses the response into JSON.\nconfig_dict = f.json()\n\n# print(config_dict)\n# print(type(config_dict))\n\ntasks_list = []\ntasks_list.append(config_dict['extract'])\ntasks_list = tasks_list + config_dict['transform']\ntasks_list.append(config_dict['load'])\n\ninput_df = \"df2\"\napp_input_param =\"zparams1\"\nprint(\"start of ETL json workflow =***********************> \", input_df)\nfor task in tasks_list:\n    input_df :object = eval(task)\n\nprint(\"End of ETL json workflow =***********************> \", input_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70062f42-9ecf-476f-88cb-533cf10520bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"start of ETL json workflow =***********************>  df2\nrun Extract\nrun Transform1\nrun Transform2\nrun Load\nEnd of ETL json workflow =***********************>  df2_Extract_Transform1_Transform2_Load\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["start of ETL json workflow =***********************>  df2\nrun Extract\nrun Transform1\nrun Transform2\nrun Load\nEnd of ETL json workflow =***********************>  df2_Extract_Transform1_Transform2_Load\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"001 ETL Framework","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1364670199275018}},"nbformat":4,"nbformat_minor":0}
