{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a41b1bd-b5a0-4fe0-b181-42899ff11462"}}},{"cell_type":"markdown","source":["# Schemas and Tables on Databricks\nIn this demonstration, you will create and explore schemas and tables.\n\n## Learning Objectives\nBy the end of this lesson, you should be able to:\n* Use Spark SQL DDL to define schemas and tables\n* Describe how the **`LOCATION`** keyword impacts the default storage directory\n\n\n\n**Resources**\n* <a href=\"https://docs.databricks.com/user-guide/tables.html\" target=\"_blank\">Schemas and Tables - Databricks Docs</a>\n* <a href=\"https://docs.databricks.com/user-guide/tables.html#managed-and-unmanaged-tables\" target=\"_blank\">Managed and Unmanaged Tables</a>\n* <a href=\"https://docs.databricks.com/user-guide/tables.html#create-a-table-using-the-ui\" target=\"_blank\">Creating a Table with the UI</a>\n* <a href=\"https://docs.databricks.com/user-guide/tables.html#create-a-local-table\" target=\"_blank\">Create a Local Table</a>\n* <a href=\"https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html#saving-to-persistent-tables\" target=\"_blank\">Saving to Persistent Tables</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4330f574-ac09-4a6c-8b22-6a9a9c29e518"}}},{"cell_type":"markdown","source":["## Lesson Setup\nThe following script clears out previous runs of this demo and configures some Hive variables that will be used in our SQL queries."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4189e8c-daf3-4a8c-aeb1-b0265380f73a"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup-03.1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68d2b8fa-26d4-4234-a637-8c6c9afd12ef"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Using Hive Variables\n\nWhile not a pattern that is generally recommended in Spark SQL, this notebook will use some Hive variables to substitute in string values derived from the account email of the current user.\n\nThe following cell demonstrates this pattern."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c20b049-286e-4ece-9b35-49c9e1355586"}}},{"cell_type":"code","source":["%sql\nSELECT \"${da.db_name}\" AS db_name,\n       \"${da.paths.working_dir}\" AS working_dir"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5966595-48aa-463d-97e8-b9c10c1323c7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Because you may be working in a shared workspace, this course uses variables derived from your username so the schemas don't conflict with other users. Again, consider this use of Hive variables a hack for our lesson environment rather than a good practice for development."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9d93c74-a579-442c-a98b-09596bc03423"}}},{"cell_type":"markdown","source":["## Schemas\nLet's start by creating two schemas:\n- One with no **`LOCATION`** specified\n- One with **`LOCATION`** specified"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"812777d5-5ffe-458c-9312-5ffcb4188378"}}},{"cell_type":"code","source":["%sql\nCREATE SCHEMA IF NOT EXISTS ${da.db_name}_default_location;\nCREATE SCHEMA IF NOT EXISTS ${da.db_name}_custom_location LOCATION '${da.paths.working_dir}/_custom_location.db';"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01249d26-8413-4de6-868c-bbc86620389f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note that the location of the first schema is in the default location under **`dbfs:/user/hive/warehouse/`** and that the schema directory is the name of the schema with the **`.db`** extension"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"beb8ddeb-4a14-4741-99fd-52398bf4bf46"}}},{"cell_type":"code","source":["%sql\nDESCRIBE SCHEMA EXTENDED ${da.db_name}_default_location;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f781607-e48c-4fe1-a10f-179249418925"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note that the location of the second schema is in the directory specified after the **`LOCATION`** keyword."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17a6dacb-97a2-4dd5-86fc-c1b6284342c8"}}},{"cell_type":"code","source":["%sql\nDESCRIBE SCHEMA EXTENDED ${da.db_name}_custom_location;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed8461db-ca4c-4649-b1d0-4a8935d0f3c3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We will create a table in the schema with default location and insert data. \n\nNote that the schema must be provided because there is no data from which to infer the schema."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26c1b58c-085f-4ac6-a53b-de4bd1573835"}}},{"cell_type":"code","source":["%sql\nUSE ${da.db_name}_default_location;\n\nCREATE OR REPLACE TABLE managed_table_in_db_with_default_location (width INT, length INT, height INT);\nINSERT INTO managed_table_in_db_with_default_location \nVALUES (3, 2, 1);\nSELECT * FROM managed_table_in_db_with_default_location;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39782b9f-c863-45d5-96a3-bc937214cd1b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can look at the extended table description to find the location (you'll need to scroll down in the results)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78ff3910-3153-4667-af50-8bae10f2ca2b"}}},{"cell_type":"code","source":["%sql\nDESCRIBE DETAIL managed_table_in_db_with_default_location;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c044cc3-5913-4e78-a3e6-cdaa175094f3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["By default, managed tables in a schema without the location specified will be created in the **`dbfs:/user/hive/warehouse/<schema_name>.db/`** directory.\n\nWe can see that, as expected, the data and metadata for our Delta Table are stored in that location."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"317face7-2108-4cfb-901c-6021dd6e6cff"}}},{"cell_type":"code","source":["%python \nhive_root =  f\"dbfs:/user/hive/warehouse\"\ndb_name =    f\"{DA.db_name}_default_location.db\"\ntable_name = f\"managed_table_in_db_with_default_location\"\n\ntbl_location = f\"{hive_root}/{db_name}/{table_name}\"\nprint(tbl_location)\n\nfiles = dbutils.fs.ls(tbl_location)\ndisplay(files)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"987e0c9d-d4a0-4129-a22b-7fe0e7cc5caa"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Drop the table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d46c2b35-a9ba-4f52-be14-68e0390257c1"}}},{"cell_type":"code","source":["%sql\nDROP TABLE managed_table_in_db_with_default_location;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc18c712-fe2f-4c0c-bcf9-2f851ca44c45"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note the table's directory and its log and data files are deleted. Only the schema directory remains."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6a2affe-6a2b-4369-aa42-134c662cd11d"}}},{"cell_type":"code","source":["%python \n\ndb_location = f\"{hive_root}/{db_name}\"\nprint(db_location)\ndbutils.fs.ls(db_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e19b288-fde8-4ccf-a153-e8270c4598dc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We now create a table in the schema with custom location and insert data. \n\nNote that the schema must be provided because there is no data from which to infer the schema."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"232c44b9-49ef-496a-88e7-3ed8e0116908"}}},{"cell_type":"code","source":["%sql\nUSE ${da.db_name}_custom_location;\n\nCREATE OR REPLACE TABLE managed_table_in_db_with_custom_location (width INT, length INT, height INT);\nINSERT INTO managed_table_in_db_with_custom_location VALUES (3, 2, 1);\nSELECT * FROM managed_table_in_db_with_custom_location;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"951adda2-42bb-4cf7-bead-879db901dea8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Again, we'll look at the description to find the table location."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1da9c52-549d-4dfa-8f3d-872ff6cc3d6c"}}},{"cell_type":"code","source":["%sql\nDESCRIBE DETAIL managed_table_in_db_with_custom_location;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48f87189-0363-4e11-8b90-bb8000a37b28"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["As expected, this managed table is created in the path specified with the **`LOCATION`** keyword during schema creation. As such, the data and metadata for the table are persisted in a directory here."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9fc69cd-9a42-415e-a197-272ae6a8f172"}}},{"cell_type":"code","source":["%python \n\ntable_name = f\"managed_table_in_db_with_custom_location\"\ntbl_location =   f\"{DA.paths.working_dir}/_custom_location.db/{table_name}\"\nprint(tbl_location)\n\nfiles = dbutils.fs.ls(tbl_location)\ndisplay(files)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f4605f2-c391-403b-a926-f91ae49bcdf4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's drop the table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c2ba05c-05c3-4c95-a5e4-155067f14123"}}},{"cell_type":"code","source":["%sql\nDROP TABLE managed_table_in_db_with_custom_location;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3b39014-e0e2-4ec3-85c2-2a20466eeb34"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note the table's folder and the log file and data file are deleted.  \n  \nOnly the schema location remains"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a7d6cf9-4ad0-4477-b9db-f384140c8fb0"}}},{"cell_type":"code","source":["%python \n\ndb_location =   f\"{DA.paths.working_dir}/_custom_location.db\"\nprint(db_location)\n\ndbutils.fs.ls(db_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89d14900-5092-41ee-aad1-4979545512f6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Tables\nWe will create an external (unmanaged) table from sample data. \n\nThe data we are going to use are in CSV format. We want to create a Delta table with a **`LOCATION`** provided in the directory of our choice."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e630fb49-880d-4073-b891-e2e0c03c6095"}}},{"cell_type":"code","source":["%sql\nUSE ${da.db_name}_default_location;\n\nCREATE OR REPLACE TEMPORARY VIEW temp_delays USING CSV OPTIONS (\n  path = '${DA.paths.datasets}/flights/departuredelays.csv',\n  header = \"true\",\n  mode = \"FAILFAST\" -- abort file parsing with a RuntimeException if any malformed lines are encountered\n);\nCREATE OR REPLACE TABLE external_table LOCATION '${da.paths.working_dir}/external_table' AS\n  SELECT * FROM temp_delays;\n\nSELECT * FROM external_table;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45e8d377-791d-41d2-afd7-8dbd507b8406"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's note the location of the table's data in this lesson's working directory."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe0c005e-c896-4aa3-a916-e2022f14f2d7"}}},{"cell_type":"code","source":["%sql\nDESCRIBE TABLE EXTENDED external_table;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fef03d70-0ac8-4667-a637-ce67701119d9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now, we drop the table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50ee4334-85ed-4e61-a4b9-0f03e0becd34"}}},{"cell_type":"code","source":["%sql\nDROP TABLE external_table;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69d94858-48c8-4bb7-8e66-0f542a18bdc7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The table definition no longer exists in the metastore, but the underlying data remain intact."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"606fc266-126f-48cb-9881-5b8616f6d0bc"}}},{"cell_type":"code","source":["%python \ntbl_path = f\"{DA.paths.working_dir}/external_table\"\nfiles = dbutils.fs.ls(tbl_path)\ndisplay(files)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9170653f-45cd-44d7-9236-330a0355bbe5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Clean up\nDrop both schemas."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0bdbb337-c5c2-4115-a989-386ec822fd92"}}},{"cell_type":"code","source":["%sql\nDROP SCHEMA ${da.db_name}_default_location CASCADE;\nDROP SCHEMA ${da.db_name}_custom_location CASCADE;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63a0f03f-89d8-40ad-a3d6-4e6065bab4c8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the following cell to delete the tables and files associated with this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"260b8f09-b68a-440a-922b-485f5e961878"}}},{"cell_type":"code","source":["%python \nDA.cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4bacaaa-9c70-4c6d-a48f-2bcd04533ed5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5ec0d7a-38b7-45f4-a110-90d84629465a"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DE 3.1 - Databases and Tables on Databricks","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2264272731308176}},"nbformat":4,"nbformat_minor":0}
